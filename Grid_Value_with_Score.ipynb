{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7897cf95-3109-400a-b733-e8addc63740c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed and Q-table saved!\n",
      "Average Score: -0.9316\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "class GridWorld:\n",
    "    def __init__(self, size=5, obstacles=5):\n",
    "        self.size = size\n",
    "        self.start = (0, 0)\n",
    "        self.goal = (4, 4)\n",
    "        self.obstacles = set()\n",
    "        self.generate_obstacles(obstacles)\n",
    "        self.reset()\n",
    "\n",
    "    def generate_obstacles(self, count):\n",
    "        while len(self.obstacles) < count:\n",
    "            x, y = random.randint(0, self.size-1), random.randint(0, self.size-1)\n",
    "            if (x, y) not in [self.start, self.goal]:\n",
    "                self.obstacles.add((x, y))\n",
    "\n",
    "    def reset(self):\n",
    "        self.agent_pos = self.start\n",
    "        return self.agent_pos\n",
    "\n",
    "    def get_actions(self, state):\n",
    "        x, y = state\n",
    "        actions = []\n",
    "        if x > 0: actions.append(\"LEFT\")\n",
    "        if x < self.size - 1: actions.append(\"RIGHT\")\n",
    "        if y > 0: actions.append(\"UP\")\n",
    "        if y < self.size - 1: actions.append(\"DOWN\")\n",
    "        return actions\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y = self.agent_pos\n",
    "        if action == \"LEFT\": x -= 1\n",
    "        if action == \"RIGHT\": x += 1\n",
    "        if action == \"UP\": y -= 1\n",
    "        if action == \"DOWN\": y += 1\n",
    "\n",
    "        new_state = (x, y)\n",
    "        reward = -1  # Default move penalty\n",
    "\n",
    "        if new_state == self.goal:\n",
    "            reward = 10  # Goal reward\n",
    "            done = True\n",
    "        elif new_state in self.obstacles:\n",
    "            reward = -5  # Obstacle penalty\n",
    "            done = False\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        self.agent_pos = new_state\n",
    "        return new_state, reward, done\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.2):\n",
    "        self.q_table = {}  # (state, action) -> Q-value\n",
    "        self.alpha = alpha  # Learning rate\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon  # Exploration rate\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.q_table.get((state, action), 0)\n",
    "\n",
    "    def choose_action(self, state, available_actions):\n",
    "        if random.uniform(0, 1) < self.epsilon:  # Explore\n",
    "            return random.choice(available_actions)\n",
    "        # Exploit: Pick best action based on Q-values\n",
    "        q_values = {a: self.get_q_value(state, a) for a in available_actions}\n",
    "        return max(q_values, key=q_values.get)\n",
    "\n",
    "    def update_q_table(self, state, action, reward, next_state, done):\n",
    "        old_value = self.get_q_value(state, action)\n",
    "        future_max = max([self.get_q_value(next_state, a) for a in [\"LEFT\", \"RIGHT\", \"UP\", \"DOWN\"]], default=0)\n",
    "        new_value = old_value + self.alpha * (reward + self.gamma * future_max * (1 - int(done)) - old_value)\n",
    "        self.q_table[(state, action)] = new_value\n",
    "\n",
    "def train_q_agent(episodes=5000):\n",
    "    env = GridWorld()\n",
    "    agent = QLearningAgent()\n",
    "    scores = []\n",
    "\n",
    "    for _ in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        total_score = 0\n",
    "\n",
    "        while not done:\n",
    "            available_actions = env.get_actions(state)\n",
    "            action = agent.choose_action(state, available_actions)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            agent.update_q_table(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_score += reward  # Accumulate score\n",
    "\n",
    "        scores.append(total_score)  # Store episode score\n",
    "\n",
    "    # Save trained Q-table\n",
    "    with open(\"grid_q_table.pkl\", \"wb\") as f:\n",
    "        pickle.dump(agent.q_table, f)\n",
    "\n",
    "    print(\"Training completed and Q-table saved!\")\n",
    "    print(f\"Average Score: {sum(scores) / len(scores)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_q_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4178bcf1-f385-499d-84fe-515104db4573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: (0, 0)\n",
      "Agent at: (0, 0)\n",
      "Agent chooses: RIGHT\n",
      "Agent at: (1, 0)\n",
      "Agent chooses: RIGHT\n",
      "Agent at: (2, 0)\n",
      "Agent chooses: RIGHT\n",
      "Agent at: (3, 0)\n",
      "Agent chooses: DOWN\n",
      "Agent at: (3, 1)\n",
      "Agent chooses: DOWN\n",
      "Agent at: (3, 2)\n",
      "Agent chooses: RIGHT\n",
      "Agent at: (4, 2)\n",
      "Agent chooses: DOWN\n",
      "Agent at: (4, 3)\n",
      "Agent chooses: LEFT\n",
      "Agent at: (3, 3)\n",
      "Agent chooses: DOWN\n",
      "Agent at: (3, 4)\n",
      "Agent chooses: RIGHT\n",
      "Final Position: (4, 4)\n",
      "Goal reached!\n",
      "Total Score: -11\n"
     ]
    }
   ],
   "source": [
    "def play_with_q_agent():\n",
    "    with open(\"grid_q_table.pkl\", \"rb\") as f:\n",
    "        q_table = pickle.load(f)\n",
    "\n",
    "    env = GridWorld()\n",
    "    agent = QLearningAgent()\n",
    "    agent.q_table = q_table  # Load trained Q-values\n",
    "\n",
    "    state = env.reset()\n",
    "    total_score = 0\n",
    "\n",
    "    print(f\"Start: {state}\")\n",
    "\n",
    "    while True:\n",
    "        print(f\"Agent at: {state}\")\n",
    "        available_actions = env.get_actions(state)\n",
    "        action = agent.choose_action(state, available_actions)\n",
    "        print(f\"Agent chooses: {action}\")\n",
    "\n",
    "        state, reward, done = env.step(action)\n",
    "        total_score += reward\n",
    "\n",
    "        if done:\n",
    "            print(f\"Final Position: {state}\")\n",
    "            print(\"Goal reached!\" if state == env.goal else \"Agent hit an obstacle!\")\n",
    "            print(f\"Total Score: {total_score}\")\n",
    "            break\n",
    "\n",
    "play_with_q_agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c134e01d-783a-4c0c-aee8-bcc79750a7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
